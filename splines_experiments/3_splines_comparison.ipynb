{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Model Selection and Comparison\n",
    "\n",
    "## Evaluating Spline Methods Across Regression and Classification Tasks\n",
    "\n",
    "**Regression (FEV Data)**:\n",
    "- Linear Regression (baseline)\n",
    "- Regression Spline (truncated power basis)\n",
    "- Natural Cubic Spline (natural boundary conditions)\n",
    "- Penalized Spline (P-spline with automatic smoothing)\n",
    "- Generalized Additive Model (multivariate smooth)\n",
    "\n",
    "**Classification (Heart Data)**:\n",
    "- Logistic Regression (baseline)\n",
    "- Logistic GAM (smooth risk functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import time\n",
    "\n",
    "from splines import RegressionSpline, NaturalCubicSpline, PenalizedSpline\n",
    "from gam import GAM, LogisticGAM\n",
    "from data_utils import load_fev_data, load_heart_data\n",
    "from utils import mean_squared_error, r_squared, classification_metrics\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('Set2')\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Regression Model Comparison (FEV Dataset)\n",
    "\n",
    "### Dataset: Forced Expiratory Volume (FEV)\n",
    "- **Objective**: Predict lung function from age\n",
    "- **Challenge**: Non-linear growth pattern\n",
    "- **Evaluation**: MSE, R², effective DF, computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fev, X_test_fev, y_train_fev, y_test_fev, features_fev = load_fev_data(\n",
    "    filepath='fev.csv',\n",
    "    standardize=True,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "x_train_age = X_train_fev[:, 0]\n",
    "x_test_age = X_test_fev[:, 0]\n",
    "\n",
    "print(f\"Training samples: {len(x_train_age)}\")\n",
    "print(f\"Test samples: {len(x_test_age)}\")\n",
    "print(f\"\\nWe'll compare spline methods for modeling FEV vs Age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit All Regression Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = []\n",
    "\n",
    "t0 = time.time()\n",
    "lm = LinearRegression()\n",
    "lm.fit(x_train_age.reshape(-1, 1), y_train_fev)\n",
    "y_pred_train = lm.predict(x_train_age.reshape(-1, 1))\n",
    "y_pred_test = lm.predict(x_test_age.reshape(-1, 1))\n",
    "train_time_lm = time.time() - t0\n",
    "\n",
    "regression_results.append({\n",
    "    'Model': 'Linear Regression',\n",
    "    'Train MSE': mean_squared_error(y_train_fev, y_pred_train),\n",
    "    'Test MSE': mean_squared_error(y_test_fev, y_pred_test),\n",
    "    'Train R²': r_squared(y_train_fev, y_pred_train),\n",
    "    'Test R²': r_squared(y_test_fev, y_pred_test),\n",
    "    'Effective DF': 2.0,\n",
    "    'Time (s)': train_time_lm\n",
    "})\n",
    "\n",
    "t0 = time.time()\n",
    "reg_spline = RegressionSpline(degree=3)\n",
    "reg_spline.fit(x_train_age, y_train_fev, knots=np.linspace(x_train_age.min(), x_train_age.max(), 8))\n",
    "y_pred_train = reg_spline.predict(x_train_age)\n",
    "y_pred_test = reg_spline.predict(x_test_age)\n",
    "train_time_rs = time.time() - t0\n",
    "\n",
    "regression_results.append({\n",
    "    'Model': 'Regression Spline',\n",
    "    'Train MSE': mean_squared_error(y_train_fev, y_pred_train),\n",
    "    'Test MSE': mean_squared_error(y_test_fev, y_pred_test),\n",
    "    'Train R²': r_squared(y_train_fev, y_pred_train),\n",
    "    'Test R²': r_squared(y_test_fev, y_pred_test),\n",
    "    'Effective DF': 8 + 3 + 1,\n",
    "    'Time (s)': train_time_rs\n",
    "})\n",
    "\n",
    "t0 = time.time()\n",
    "nat_spline = NaturalCubicSpline()\n",
    "knots_nat = np.linspace(x_train_age.min(), x_train_age.max(), 8)\n",
    "nat_spline.fit(x_train_age, y_train_fev, knots=np.concatenate([[x_train_age.min(), x_train_age.max()], knots_nat]))\n",
    "y_pred_train = nat_spline.predict(x_train_age)\n",
    "y_pred_test = nat_spline.predict(x_test_age)\n",
    "train_time_ns = time.time() - t0\n",
    "\n",
    "regression_results.append({\n",
    "    'Model': 'Natural Cubic Spline',\n",
    "    'Train MSE': mean_squared_error(y_train_fev, y_pred_train),\n",
    "    'Test MSE': mean_squared_error(y_test_fev, y_pred_test),\n",
    "    'Train R²': r_squared(y_train_fev, y_pred_train),\n",
    "    'Test R²': r_squared(y_test_fev, y_pred_test),\n",
    "    'Effective DF': 8.0,\n",
    "    'Time (s)': train_time_ns\n",
    "})\n",
    "\n",
    "t0 = time.time()\n",
    "p_spline = PenalizedSpline(n_knots=15, degree=3, diff_order=2)\n",
    "lambdas_cv = np.logspace(-2, 2, 20)\n",
    "best_lambda, _ = p_spline.cross_validate(x_train_age, y_train_fev, lambdas_cv, cv_folds=5)\n",
    "p_spline.lambda_ = best_lambda\n",
    "p_spline.fit(x_train_age, y_train_fev)\n",
    "y_pred_train = p_spline.predict(x_train_age)\n",
    "y_pred_test = p_spline.predict(x_test_age)\n",
    "train_time_ps = time.time() - t0\n",
    "\n",
    "regression_results.append({\n",
    "    'Model': f'P-Spline (λ={best_lambda:.2f})',\n",
    "    'Train MSE': mean_squared_error(y_train_fev, y_pred_train),\n",
    "    'Test MSE': mean_squared_error(y_test_fev, y_pred_test),\n",
    "    'Train R²': r_squared(y_train_fev, y_pred_train),\n",
    "    'Test R²': r_squared(y_test_fev, y_pred_test),\n",
    "    'Effective DF': p_spline.effective_df(),\n",
    "    'Time (s)': train_time_ps\n",
    "})\n",
    "\n",
    "t0 = time.time()\n",
    "gam = GAM(\n",
    "    smooth_features=[0, 1],\n",
    "    linear_features=[2, 3],\n",
    "    n_knots=[10, 10],\n",
    "    lambda_=[1.0, 1.0],\n",
    "    degree=3,\n",
    "    max_iter=100,\n",
    "    tol=1e-4\n",
    ")\n",
    "gam.fit(X_train_fev, y_train_fev, verbose=False)\n",
    "y_pred_train = gam.predict(X_train_fev)\n",
    "y_pred_test = gam.predict(X_test_fev)\n",
    "train_time_gam = time.time() - t0\n",
    "\n",
    "regression_results.append({\n",
    "    'Model': 'GAM (4 features)',\n",
    "    'Train MSE': mean_squared_error(y_train_fev, y_pred_train),\n",
    "    'Test MSE': mean_squared_error(y_test_fev, y_pred_test),\n",
    "    'Train R²': r_squared(y_train_fev, y_pred_train),\n",
    "    'Test R²': r_squared(y_test_fev, y_pred_test),\n",
    "    'Effective DF': gam.summary()['total_edf'],\n",
    "    'Time (s)': train_time_gam\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reg = pd.DataFrame(regression_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(\"REGRESSION MODEL COMPARISON - FEV DATASET\")\n",
    "print(\"=\"*90)\n",
    "print(df_reg.to_string(index=False))\n",
    "\n",
    "best_model_idx = df_reg['Test MSE'].idxmin()\n",
    "best_model = df_reg.loc[best_model_idx, 'Model']\n",
    "best_test_r2 = df_reg.loc[best_model_idx, 'Test R²']\n",
    "\n",
    "print(\"\\n\" + \"=\"*90)\n",
    "print(f\"WINNER: {best_model} (Test R² = {best_test_r2:.3f})\")\n",
    "print(\"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "axes[0, 0].barh(df_reg['Model'], df_reg['Test R²'], color='steelblue')\n",
    "axes[0, 0].set_xlabel('Test R²', fontsize=11)\n",
    "axes[0, 0].set_title('Model Performance (Higher is Better)', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "axes[0, 1].barh(df_reg['Model'], df_reg['Effective DF'], color='darkgreen')\n",
    "axes[0, 1].set_xlabel('Effective Degrees of Freedom', fontsize=11)\n",
    "axes[0, 1].set_title('Model Complexity', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "axes[1, 0].scatter(df_reg['Effective DF'], df_reg['Test MSE'], s=200, \n",
    "                   c=df_reg['Train MSE'], cmap='RdYlGn_r', edgecolors='black', linewidth=2)\n",
    "for i, model in enumerate(df_reg['Model']):\n",
    "    axes[1, 0].annotate(model, (df_reg['Effective DF'].iloc[i], df_reg['Test MSE'].iloc[i]),\n",
    "                       fontsize=8, ha='right', va='bottom')\n",
    "axes[1, 0].set_xlabel('Effective DF (Complexity)', fontsize=11)\n",
    "axes[1, 0].set_ylabel('Test MSE', fontsize=11)\n",
    "axes[1, 0].set_title('Bias-Variance Tradeoff', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1, 1].barh(df_reg['Model'], df_reg['Time (s)'], color='darkorange')\n",
    "axes[1, 1].set_xlabel('Training Time (seconds)', fontsize=11)\n",
    "axes[1, 1].set_title('Computational Efficiency', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"✓ {best_model} achieves best test R²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Classification Model Comparison (Heart Dataset)\n",
    "\n",
    "### Dataset: South African Heart Disease\n",
    "- **Objective**: Predict CHD from risk factors\n",
    "- **Challenge**: Non-linear risk relationships\n",
    "- **Evaluation**: AUC, accuracy, precision, recall, effective DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_heart, X_test_heart, y_train_heart, y_test_heart, features_heart = load_heart_data(\n",
    "    filepath='Heart.csv',\n",
    "    standardize=True,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(y_train_heart)}\")\n",
    "print(f\"Test samples: {len(y_test_heart)}\")\n",
    "print(f\"CHD prevalence (train): {np.mean(y_train_heart)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit All Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results = []\n",
    "\n",
    "print(\"[1/2] Logistic Regression...\")\n",
    "t0 = time.time()\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_heart, y_train_heart)\n",
    "y_pred_proba_train = lr.predict_proba(X_train_heart)[:, 1]\n",
    "y_pred_proba_test = lr.predict_proba(X_test_heart)[:, 1]\n",
    "train_time_lr = time.time() - t0\n",
    "\n",
    "train_metrics = classification_metrics(y_train_heart, y_pred_proba_train)\n",
    "test_metrics = classification_metrics(y_test_heart, y_pred_proba_test)\n",
    "\n",
    "classification_results.append({\n",
    "    'Model': 'Logistic Regression',\n",
    "    'Train AUC': train_metrics['auc_roc'],\n",
    "    'Test AUC': test_metrics['auc_roc'],\n",
    "    'Test Accuracy': test_metrics['accuracy'],\n",
    "    'Test Precision': test_metrics['precision'],\n",
    "    'Test Recall': test_metrics['recall'],\n",
    "    'Effective DF': 10.0,\n",
    "    'Time (s)': train_time_lr\n",
    "})\n",
    "\n",
    "print(\"[2/2] Logistic GAM...\")\n",
    "t0 = time.time()\n",
    "log_gam = LogisticGAM(\n",
    "    smooth_features=[8, 0, 1, 2],\n",
    "    linear_features=[4],\n",
    "    n_knots=[8, 8, 8, 8],\n",
    "    lambda_=[1.0, 1.0, 1.0, 1.0],\n",
    "    degree=3,\n",
    "    max_iter=25,\n",
    "    tol=1e-4\n",
    ")\n",
    "log_gam.fit(X_train_heart, y_train_heart, verbose=False)\n",
    "y_pred_proba_train = log_gam.predict_proba(X_train_heart)\n",
    "y_pred_proba_test = log_gam.predict_proba(X_test_heart)\n",
    "train_time_gam = time.time() - t0\n",
    "\n",
    "train_metrics = classification_metrics(y_train_heart, y_pred_proba_train)\n",
    "test_metrics = classification_metrics(y_test_heart, y_pred_proba_test)\n",
    "\n",
    "classification_results.append({\n",
    "    'Model': 'Logistic GAM',\n",
    "    'Train AUC': train_metrics['auc_roc'],\n",
    "    'Test AUC': test_metrics['auc_roc'],\n",
    "    'Test Accuracy': test_metrics['accuracy'],\n",
    "    'Test Precision': test_metrics['precision'],\n",
    "    'Test Recall': test_metrics['recall'],\n",
    "    'Effective DF': log_gam.summary()['total_edf'],\n",
    "    'Time (s)': train_time_gam\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = pd.DataFrame(classification_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"CLASSIFICATION MODEL COMPARISON - HEART DISEASE DATASET\")\n",
    "print(\"=\"*100)\n",
    "print(df_clf.to_string(index=False))\n",
    "\n",
    "best_model_idx = df_clf['Test AUC'].idxmax()\n",
    "best_model = df_clf.loc[best_model_idx, 'Model']\n",
    "best_test_auc = df_clf.loc[best_model_idx, 'Test AUC']\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(f\"WINNER: {best_model} (Test AUC = {best_test_auc:.3f})\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "x_pos = np.arange(len(df_clf))\n",
    "axes[0, 0].bar(x_pos - 0.2, df_clf['Train AUC'], 0.4, label='Train AUC', color='steelblue')\n",
    "axes[0, 0].bar(x_pos + 0.2, df_clf['Test AUC'], 0.4, label='Test AUC', color='darkred')\n",
    "axes[0, 0].set_xticks(x_pos)\n",
    "axes[0, 0].set_xticklabels(df_clf['Model'])\n",
    "axes[0, 0].set_ylabel('AUC-ROC', fontsize=11)\n",
    "axes[0, 0].set_title('Discriminative Performance', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "axes[0, 1].scatter(df_clf['Test Recall'], df_clf['Test Precision'], s=300, \n",
    "                   c=['steelblue', 'darkred'], edgecolors='black', linewidth=2)\n",
    "for i, model in enumerate(df_clf['Model']):\n",
    "    axes[0, 1].annotate(model, (df_clf['Test Recall'].iloc[i], df_clf['Test Precision'].iloc[i]),\n",
    "                       fontsize=10, ha='center', va='bottom')\n",
    "axes[0, 1].set_xlabel('Recall (Sensitivity)', fontsize=11)\n",
    "axes[0, 1].set_ylabel('Precision', fontsize=11)\n",
    "axes[0, 1].set_title('Precision-Recall Tradeoff', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "axes[0, 1].set_xlim([0.5, 1.0])\n",
    "axes[0, 1].set_ylim([0.5, 1.0])\n",
    "\n",
    "axes[1, 0].barh(df_clf['Model'], df_clf['Effective DF'], color='darkgreen')\n",
    "axes[1, 0].set_xlabel('Effective Degrees of Freedom', fontsize=11)\n",
    "axes[1, 0].set_title('Model Complexity', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "metrics_to_plot = ['Test AUC', 'Test Accuracy', 'Test Precision', 'Test Recall']\n",
    "for i, model in enumerate(df_clf['Model']):\n",
    "    values = [df_clf.loc[i, m] for m in metrics_to_plot]\n",
    "    axes[1, 1].plot(metrics_to_plot, values, 'o-', linewidth=2.5, markersize=10, label=model)\n",
    "axes[1, 1].set_ylabel('Score', fontsize=11)\n",
    "axes[1, 1].set_title('Comprehensive Performance Profile', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_ylim([0.6, 1.0])\n",
    "plt.setp(axes[1, 1].xaxis.get_majorticklabels(), rotation=15, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights:\")\n",
    "print(f\"✓ {best_model} achieves best AUC ({best_test_auc:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Comparison Across All Methods\n",
    "\n",
    "## Key Insights from Model Comparison\n",
    "\n",
    "### Regression Methods (FEV Dataset):\n",
    "1. **Performance**: GAM achieves the best test R² (0.789) by leveraging multiple predictors\n",
    "2. **Complexity**: P-splines offer the best balance of flexibility and efficiency\n",
    "3. **Computation**: Linear regression is fastest, but GAM provides much better fit\n",
    "4. **Bias-Variance Tradeoff**: Natural splines reduce boundary variance at the cost of some flexibility\n",
    "\n",
    "### Classification Methods (Heart Disease Dataset):\n",
    "1. **Discrimination**: Both logistic regression and Logistic GAM achieve similar AUC (~0.75)\n",
    "2. **Interpretability**: Logistic GAM provides detailed risk profiles for each predictor\n",
    "3. **Complexity**: Logistic GAM uses more effective degrees of freedom but captures non-linearities\n",
    "4. **Clinical Utility**: GAM can identify threshold effects that linear models miss\n",
    "\n",
    "### General Observations:\n",
    "1. **Model Selection**: The \"best\" model depends on the specific task and evaluation metric\n",
    "2. **Overfitting Risk**: More complex models (GAM, splines) require careful regularization\n",
    "3. **Computational Cost**: P-splines and GAM are more computationally intensive but offer better performance\n",
    "4. **Interpretability Tradeoff**: Linear models are most interpretable, GAMs offer interpretability with flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison table\n",
    "summary_comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Task': 'Regression (FEV)',\n",
    "        'Best Model': best_model,\n",
    "        'Performance': f\"R² = {best_test_r2:.3f}\",\n",
    "        'Key Advantage': 'Multivariate non-linear modeling',\n",
    "        'Tradeoff': 'Higher complexity and computation time'\n",
    "    },\n",
    "    {\n",
    "        'Task': 'Classification (Heart)',\n",
    "        'Best Model': best_model,\n",
    "        'Performance': f\"AUC = {best_test_auc:.3f}\",\n",
    "        'Key Advantage': 'Non-linear risk functions',\n",
    "        'Tradeoff': 'Slightly more complex interpretation'\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"COMPREHENSIVE MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\"*100)\n",
    "print(summary_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Each Method:\n",
    "\n",
    "1. **Linear Regression/Logistic Regression**:\n",
    "   - When relationships are approximately linear\n",
    "   - When interpretability is paramount\n",
    "   - When computational resources are limited\n",
    "   - As a baseline for comparison\n",
    "\n",
    "2. **Regression Splines**:\n",
    "   - When you have domain knowledge about knot locations\n",
    "   - When you need explicit control over flexibility\n",
    "   - For educational purposes to understand spline construction\n",
    "\n",
    "3. **Natural Cubic Splines**:\n",
    "   - When data is sparse at boundaries\n",
    "   - When linear extrapolation is more reasonable than cubic\n",
    "   - When you want fewer parameters than regression splines\n",
    "\n",
    "4. **Smoothing Splines**:\n",
    "   - When you want automatic knot placement\n",
    "   - When you prefer a single tuning parameter\n",
    "   - For theoretical understanding of functional data analysis\n",
    "\n",
    "5. **P-splines**:\n",
    "   - For practical applications\n",
    "   - When you need computational efficiency\n",
    "   - When working with large datasets\n",
    "   - For robust performance across different data types\n",
    "\n",
    "6. **GAMs**:\n",
    "   - When you have multiple predictors with potentially non-linear relationships\n",
    "   - When you want to maintain interpretability while capturing complexity\n",
    "   - For scientific inference where understanding individual effects matters\n",
    "   - When you need both smooth and linear terms in the same model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
