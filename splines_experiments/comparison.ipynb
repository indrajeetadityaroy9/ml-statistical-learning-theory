{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprehensive Comparison and Real-World Applications\n",
    "Comprehensive comparison of all spline methods and compares with scipy/statsmodels implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from splines import RegressionSpline, NaturalCubicSpline, SmoothingSpline\n",
    "from utils import (\n",
    "    generate_sinusoidal_data,\n",
    "    mean_squared_error,\n",
    "    r_squared\n",
    ")\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Side-by-Side Comparison: All Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(42)\n",
    "x_train, y_train = generate_sinusoidal_data(n_samples=50, noise_std=0.25, x_range=(0, 10))\n",
    "x_test = np.linspace(0, 10, 500)\n",
    "y_true = np.sin(2*np.pi*x_test/10)\n",
    "\n",
    "# Setup\n",
    "manual_knots = np.linspace(2, 8, 6)\n",
    "all_knots = np.sort(np.concatenate([[0, 10], manual_knots]))\n",
    "\n",
    "# Fit all models\n",
    "models = {}\n",
    "\n",
    "# 1. Regular regression spline\n",
    "reg_model = RegressionSpline(degree=3)\n",
    "reg_model.fit(x_train, y_train, manual_knots)\n",
    "models['Regular Spline'] = reg_model.predict(x_test)\n",
    "\n",
    "# 2. Natural cubic spline\n",
    "nat_model = NaturalCubicSpline()\n",
    "nat_model.fit(x_train, y_train, all_knots)\n",
    "models['Natural Spline'] = nat_model.predict(x_test)\n",
    "\n",
    "# 3. Smoothing spline (optimal lambda via CV)\n",
    "smooth_model = SmoothingSpline()\n",
    "lambdas = np.logspace(-3, 1, 20)\n",
    "best_lam, _ = smooth_model.cross_validate(x_train, y_train, lambdas, cv_folds=5)\n",
    "smooth_model = SmoothingSpline(lambda_=best_lam)\n",
    "smooth_model.fit(x_train, y_train)\n",
    "models['Smoothing Spline'] = smooth_model.predict(x_test)\n",
    "\n",
    "# 4. Global polynomial (for comparison)\n",
    "poly_deg = 9\n",
    "poly_coeffs = np.polyfit(x_train, y_train, poly_deg)\n",
    "models['Polynomial (deg 9)'] = np.polyval(poly_coeffs, x_test)\n",
    "\n",
    "# Plot all\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "ax.scatter(x_train, y_train, alpha=0.4, s=30, label='Data', color='gray', zorder=3)\n",
    "ax.plot(x_test, y_true, 'k--', linewidth=2.5, alpha=0.5, label='True function', zorder=1)\n",
    "\n",
    "colors = ['blue', 'purple', 'red', 'orange']\n",
    "linestyles = ['-', '--', '-.', ':']\n",
    "for (name, y_pred), color, ls in zip(models.items(), colors, linestyles):\n",
    "    ax.plot(x_test, y_pred, color=color, linestyle=ls, linewidth=2, label=name, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('x', fontsize=13)\n",
    "ax.set_ylabel('y', fontsize=13)\n",
    "ax.set_title('Comparison of All Spline Methods', fontsize=15)\n",
    "ax.legend(fontsize=11, loc='upper right')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compute metrics\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"{'Method':<25} {'Training MSE':<15} {'Training R²':<15} {'Test MSE':<15}\")\n",
    "print(\"=\"*80)\n",
    "for name in models.keys():\n",
    "    if name == 'Regular Spline':\n",
    "        y_pred_train = reg_model.predict(x_train)\n",
    "    elif name == 'Natural Spline':\n",
    "        y_pred_train = nat_model.predict(x_train)\n",
    "    elif name == 'Smoothing Spline':\n",
    "        y_pred_train = smooth_model.predict(x_train)\n",
    "    else:\n",
    "        y_pred_train = np.polyval(poly_coeffs, x_train)\n",
    "    \n",
    "    train_mse = mean_squared_error(y_train, y_pred_train)\n",
    "    train_r2 = r_squared(y_train, y_pred_train)\n",
    "    test_mse = mean_squared_error(y_true, models[name])\n",
    "    \n",
    "    print(f\"{name:<25} {train_mse:<15.4f} {train_r2:<15.4f} {test_mse:<15.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Comparison with SciPy UnivariateSpline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_model = SmoothingSpline(lambda_=0.1)\n",
    "cur_model.fit(x_train, y_train)\n",
    "y_cur = cur_model.predict(x_test)\n",
    "\n",
    "# SciPy implementation (uses B-spline basis)\n",
    "# Note: scipy's 's' parameter is related to smoothing, lower = less smooth\n",
    "scipy_model = UnivariateSpline(x_train, y_train, s=5.0, k=3)\n",
    "y_scipy = scipy_model(x_test)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.scatter(x_train, y_train, alpha=0.5, s=30, label='Data', color='gray', zorder=3)\n",
    "ax.plot(x_test, y_cur, 'b-', linewidth=2.5, label='Current Smoothing Spline', alpha=0.8)\n",
    "ax.plot(x_test, y_scipy, 'r--', linewidth=2.5, label='SciPy UnivariateSpline', alpha=0.8)\n",
    "ax.plot(x_test, y_true, 'g:', linewidth=2, label='True function', alpha=0.5)\n",
    "\n",
    "ax.set_xlabel('x', fontsize=12)\n",
    "ax.set_ylabel('y', fontsize=12)\n",
    "ax.set_title('Current Implementation vs SciPy', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Compare\n",
    "diff = np.abs(y_cur - y_scipy)\n",
    "print(f\"\\nMax absolute difference: {np.max(diff):.4f}\")\n",
    "print(f\"Mean absolute difference: {np.mean(diff):.4f}\")\n",
    "print(\"\\nNote: Some difference expected due to:\")\n",
    "print(\"  - SciPy uses B-spline basis (more numerically stable)\")\n",
    "print(\"  - Different parameterizations of smoothing parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Performance on Different Data Characteristics\n",
    "\n",
    "Test all methods on different types of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_polynomial_data, generate_step_data, generate_discontinuous_data\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "# Different data types\n",
    "datasets = [\n",
    "    ('Smooth (Sine)', *generate_sinusoidal_data(50, 0.2, (0, 10))),\n",
    "    ('Polynomial', *generate_polynomial_data(50, 4, 0.3, (-1, 1))),\n",
    "    ('Step Function', *generate_step_data(50, 4, 0.2, (0, 10))),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(len(datasets), 1, figsize=(12, 4*len(datasets)))\n",
    "\n",
    "for ax, (name, x_train, y_train) in zip(axes, datasets):\n",
    "    x_test = np.linspace(np.min(x_train), np.max(x_train), 500)\n",
    "    \n",
    "    # Fit models\n",
    "    # Smoothing spline\n",
    "    smooth_model = SmoothingSpline(lambda_=0.1)\n",
    "    smooth_model.fit(x_train, y_train)\n",
    "    y_smooth = smooth_model.predict(x_test)\n",
    "    \n",
    "    # Regular spline with fixed knots\n",
    "    n_knots = min(6, len(x_train) // 8)\n",
    "    knots = np.linspace(np.min(x_train), np.max(x_train), n_knots)[1:-1]\n",
    "    if len(knots) > 0:\n",
    "        reg_model = RegressionSpline(degree=3)\n",
    "        reg_model.fit(x_train, y_train, knots)\n",
    "        y_reg = reg_model.predict(x_test)\n",
    "    else:\n",
    "        y_reg = np.polyval(np.polyfit(x_train, y_train, 3), x_test)\n",
    "    \n",
    "    # Plot\n",
    "    ax.scatter(x_train, y_train, alpha=0.5, s=30, color='gray', zorder=3, label='Data')\n",
    "    ax.plot(x_test, y_smooth, 'b-', linewidth=2, label='Smoothing Spline', alpha=0.8)\n",
    "    ax.plot(x_test, y_reg, 'r--', linewidth=2, label='Regular Spline', alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('x', fontsize=11)\n",
    "    ax.set_ylabel('y', fontsize=11)\n",
    "    ax.set_title(f'{name}', fontsize=13)\n",
    "    ax.legend(fontsize=10)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"  - Smoothing splines handle ALL data types well\")\n",
    "print(\"  - Regular splines sensitive to knot placement\")\n",
    "print(\"  - Step functions challenge smooth methods (expected)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Computational Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Test on different dataset sizes\n",
    "sizes = [20, 50, 100, 200]\n",
    "times_regular = []\n",
    "times_smooth = []\n",
    "times_scipy = []\n",
    "\n",
    "for n in sizes:\n",
    "    x_train, y_train = generate_sinusoidal_data(n, 0.2, (0, 10), random_state=42)\n",
    "    \n",
    "    # Regular spline\n",
    "    knots = np.linspace(2, 8, min(6, n//10))\n",
    "    start = time.time()\n",
    "    reg_model = RegressionSpline(degree=3)\n",
    "    reg_model.fit(x_train, y_train, knots)\n",
    "    _ = reg_model.predict(x_train)\n",
    "    times_regular.append(time.time() - start)\n",
    "    \n",
    "    if n <= 100:  # Only test on smaller datasets\n",
    "        start = time.time()\n",
    "        smooth_model = SmoothingSpline(lambda_=0.1)\n",
    "        smooth_model.fit(x_train, y_train)\n",
    "        _ = smooth_model.predict(x_train)\n",
    "        times_smooth.append(time.time() - start)\n",
    "    else:\n",
    "        times_smooth.append(np.nan)\n",
    "    \n",
    "    # SciPy (fast, uses B-splines)\n",
    "    start = time.time()\n",
    "    scipy_model = UnivariateSpline(x_train, y_train, s=5.0, k=3)\n",
    "    _ = scipy_model(x_train)\n",
    "    times_scipy.append(time.time() - start)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.plot(sizes, times_regular, 'o-', linewidth=2, markersize=8, label='Regular Spline')\n",
    "ax.plot(sizes[:len([t for t in times_smooth if not np.isnan(t)])], \n",
    "        [t for t in times_smooth if not np.isnan(t)], \n",
    "        's-', linewidth=2, markersize=8, label='Current Smoothing Spline')\n",
    "ax.plot(sizes, times_scipy, '^-', linewidth=2, markersize=8, label='SciPy UnivariateSpline')\n",
    "\n",
    "ax.set_xlabel('Dataset size (n)', fontsize=12)\n",
    "ax.set_ylabel('Time (seconds)', fontsize=12)\n",
    "ax.set_title('Computational Performance Comparison', fontsize=14)\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPerformance notes:\")\n",
    "print(\"  - Regular splines: Fast (simple least squares)\")\n",
    "print(\"  - Current smoothing spline: Slow (numerical integration for penalty matrix)\")\n",
    "print(\"  - SciPy: Very fast (optimized C code, B-spline basis)\")\n",
    "print(\"\\n  → For production use, prefer SciPy or implement B-spline basis!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method Comparison Summary\n",
    "\n",
    "| Method | Pros | Cons | When to Use |\n",
    "|--------|------|------|-------------|\n",
    "| **Regular Regression Spline** | Simple, fast, interpretable | Requires manual knot selection, boundary variance | Known functional form, few knots needed |\n",
    "| **Natural Cubic Spline** | Reduced boundary variance, fewer parameters | Still requires knot selection | Extrapolation important, sparse boundaries |\n",
    "| **Smoothing Spline** | Automatic knots, single tuning parameter | Computationally expensive (with truncated basis) | Unknown functional form, automatic tuning desired |\n",
    "| **Global Polynomial** | Very simple | Poor local control, numerical instability | Very smooth functions, low degree |\n",
    "\n",
    "1. **Truncated power basis**:\n",
    "   - Natural parametrization: $g_1(x)=1, g_2(x)=x, \\dots, g_{k+1}(x)=x^k, g_{k+1+j}(x)=(x-t_j)_+^k$\n",
    "   - Numerically unstable for large datasets\n",
    "   \n",
    "2. **B-spline basis** (not implemented here):\n",
    "   - \"A much better computational choice, both for speed and numerical accuracy\"\n",
    "   - \"Pretty much the standard in software\"\n",
    "   - Use `scipy.interpolate` for production code\n",
    "\n",
    "3. **Smoothing splines**:\n",
    "   - Motivated from functional perspective: $\\min_f \\sum(y_i-f(x_i))^2 + \\lambda\\int(f'')^2dx$\n",
    "   - \"Often deliver similar fits to kernel regression...in a sense simpler\"\n",
    "   - Only one tuning parameter (λ) vs kernel regression (bandwidth h + kernel choice)\n",
    "\n",
    "\n",
    "Use `scipy.interpolate.UnivariateSpline` or `statsmodels`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
